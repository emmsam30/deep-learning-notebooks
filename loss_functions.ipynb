{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap with Datasets \n",
    "$D = \\{(x_i, y_i)\\}_{i=1}^{N} \\quad \\text{where} \\quad (x_i, y_i) \\sim P(X, Y)$\n",
    "\n",
    "#### Loss function:\n",
    "$l(\\theta | x_i, y_i)$\n",
    "\n",
    "#### Expected loss:\n",
    "$L(\\theta | D) = \\mathbb{E}_{(x,y) \\sim D} [l(\\theta | x, y)]$\n",
    "\n",
    "\n",
    "We optimize the expected loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a simple linear model with 10 inputs and 1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Linear(10, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 20 samples, each with 10 features. And also 20 labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=tensor([[-0.2375, -0.8723,  0.5362,  0.7903, -0.0491,  0.9922, -2.5445, -0.4925,\n",
      "          0.8618, -0.3821],\n",
      "        [-0.3174,  0.2866, -0.1397,  0.8998, -0.6633,  0.4263,  0.7927, -1.4362,\n",
      "         -2.0186,  0.3300],\n",
      "        [ 1.6627,  0.4237,  0.9898,  1.1566, -0.3990,  0.4905, -1.5666,  1.1104,\n",
      "          0.0129, -1.1409],\n",
      "        [-0.6615,  0.3606,  0.3081, -0.5272, -0.1831,  0.1797, -0.8463, -1.4233,\n",
      "         -0.3656, -0.2409],\n",
      "        [ 2.0652,  0.0823,  0.4148,  0.3738, -0.8232,  0.2528, -0.4196,  0.3449,\n",
      "         -0.6813, -0.0383],\n",
      "        [-0.4550, -1.3191, -0.5685,  0.4255, -0.9612, -0.2849,  1.7180, -2.3235,\n",
      "          1.3412,  0.3782],\n",
      "        [ 1.1008,  0.1599, -0.4455, -0.4049, -0.5067, -0.7895,  0.0854,  0.3949,\n",
      "         -1.1136, -0.1814],\n",
      "        [ 2.0084, -1.2943,  2.0866,  0.9067,  1.3827, -0.4147, -1.6592, -0.9102,\n",
      "         -1.4861, -1.1408],\n",
      "        [ 0.5492,  0.0761,  0.9751, -0.1177,  1.1501, -0.4688, -1.0472,  0.3772,\n",
      "         -0.6103, -0.6961],\n",
      "        [-2.4141, -1.7426, -0.4425,  0.0982, -0.5886, -0.2798, -0.5757, -0.7978,\n",
      "         -0.4400, -0.2445],\n",
      "        [-0.2275,  0.5695, -0.4361, -0.3693,  0.3401, -0.5028,  0.9782, -1.0374,\n",
      "          0.2027, -0.1119],\n",
      "        [-0.5659,  0.9932, -1.3836, -0.9724, -1.2548, -0.9495, -0.3834,  1.1268,\n",
      "          0.3767, -1.8917],\n",
      "        [-0.8537,  0.0936, -0.9250,  0.7463,  0.6190,  0.7035, -0.1575,  1.4642,\n",
      "         -0.8686,  0.8650],\n",
      "        [ 0.3897,  1.4610, -0.8348, -0.3053,  0.7758,  0.7820,  1.4208, -0.1079,\n",
      "          0.2351,  0.7878],\n",
      "        [-0.5838, -2.0113, -0.5344,  0.2995, -1.1970, -0.3659, -0.8293,  0.6231,\n",
      "         -0.5036,  0.2163],\n",
      "        [ 1.0330, -0.4605, -0.4327, -0.3012, -1.0904, -1.6113, -0.8968,  1.0417,\n",
      "          1.5310, -0.1494],\n",
      "        [-2.2051,  2.1230, -1.3680, -0.3788, -0.5017, -0.5320,  0.1847,  1.1788,\n",
      "         -0.6745, -1.6198],\n",
      "        [ 0.1909, -0.4622,  0.0852,  0.3086,  1.1126, -0.8282, -0.6716,  0.5831,\n",
      "         -0.4531, -0.8124],\n",
      "        [-1.5578, -0.1984,  0.2124,  0.4082, -1.5819, -0.1563, -1.3233, -0.6100,\n",
      "          0.0981, -0.7069],\n",
      "        [-0.1860, -1.4460, -0.9676, -1.3350,  0.5409,  1.8678,  0.0304, -2.0217,\n",
      "          1.2307,  0.0113]]) y=tensor([[ 0.1544],\n",
      "        [-0.1803],\n",
      "        [ 1.8012],\n",
      "        [-1.3830],\n",
      "        [ 0.1857],\n",
      "        [-2.0583],\n",
      "        [ 0.3580],\n",
      "        [-1.3744],\n",
      "        [-1.7215],\n",
      "        [-0.4961],\n",
      "        [-0.2779],\n",
      "        [-0.3561],\n",
      "        [ 2.0074],\n",
      "        [ 0.9237],\n",
      "        [-0.7562],\n",
      "        [ 0.3011],\n",
      "        [-0.8132],\n",
      "        [ 1.3076],\n",
      "        [-2.0005],\n",
      "        [-0.4993]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(20, 10)\n",
    "y = torch.randn(20, 1)\n",
    "print(f'{x=} {y=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass through model with x, we get predictions for y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5258],\n",
      "        [-0.8593],\n",
      "        [ 0.0161],\n",
      "        [-0.5969],\n",
      "        [-0.0445],\n",
      "        [-0.0775],\n",
      "        [-0.1613],\n",
      "        [-0.4886],\n",
      "        [-0.3789],\n",
      "        [-0.8068],\n",
      "        [-0.2842],\n",
      "        [ 0.1432],\n",
      "        [-0.8723],\n",
      "        [-0.4012],\n",
      "        [-0.4084],\n",
      "        [ 0.5388],\n",
      "        [-0.4569],\n",
      "        [-0.3897],\n",
      "        [-0.3761],\n",
      "        [-0.6417]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pred_y = model(x)\n",
    "print(pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean Squared Error (MSE) Formula**\n",
    "\n",
    "The Mean Squared Error (MSE) measures the average squared difference between actual and predicted values:\n",
    "\n",
    "\n",
    "$MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$\n",
    "\n",
    "A lower MSE indicates a better fit of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3900, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.mse_loss(pred_y, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3900, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mse_loss(pred_y, y):\n",
    "    return torch.mean((pred_y - y) ** 2)\n",
    "mse_loss(pred_y, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create 20 binary labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "y = (torch.randn(20, 1) > 0).float()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Cross Entropy with Logits (BCE with Logits)\n",
    "\n",
    "Binary Cross Entropy with Logits is used for binary classification tasks. Instead of working with probabilities, it takes raw model outputs (logits) and applies the **sigmoid function** internally for stability.\n",
    "\n",
    "#### **Formula:**\n",
    "$\n",
    "L = -\\frac{1}{n} \\sum_{i=1}^{n} \\left[ y_i \\log(\\sigma(\\hat{y}_i)) + (1 - y_i) \\log(1 - \\sigma(\\hat{y}_i)) \\right]\n",
    "$\n",
    "\n",
    "\n",
    "Using logits instead of probabilities improves numerical stability and gradient computations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6922, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(pred_y, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new model that takes in 10 inputs and outputs 3 different classes\n",
    "\n",
    "Let's also create some labels of classes 0 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 0, 2, 1, 2, 1, 1, 0, 1, 1, 1, 1, 2, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "num_classes = 3\n",
    "model = torch.nn.Linear(10, num_classes)\n",
    "y = (torch.randn(20) > 0).long() + (torch.randn(20) > 0).long()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy Loss\n",
    "\n",
    "Cross Entropy is used for classification tasks to compare the predicted probability distribution with the true class labels.\n",
    "\n",
    "**Formula for a Single Sample:**\n",
    "\n",
    "$L = -\\sum_{i=1}^{C} y_i \\log(\\hat{y}_i)$\n",
    "\n",
    "**Formula for Multiple Samples:**\n",
    "\n",
    "$L = -\\frac{1}{n} \\sum_{j=1}^{n} \\sum_{i=1}^{C} y_{j,i} \\log(\\hat{y}_{j,i})$\n",
    "\n",
    "\n",
    "Cross entropy penalizes incorrect predictions more severely when the confidence in a wrong class is high.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0760, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pred_y = model(x)\n",
    "loss = torch.nn.functional.cross_entropy(pred_y, y)\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
